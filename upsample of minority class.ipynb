{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.value_counts(df_train_transform.Collision_Severity, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  from sklearn.metrics import accuracy_score,f1_score\n",
    "# majority_class = df_train_transform.Collision_Severity.mode()[0]\n",
    "# # y_pred = np.full(shape = df_train_transform.Collision_Severity.shape, fill_value = majority_class)\n",
    "# accuracy_score(df_train_transform.Collision_Severity, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "# roc_auc_score(df_train_transform.Collision_Severity, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Accident_train.csv\")\n",
    "df_test = pd.read_csv(\"Accident_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : Records: 10043 \n",
      "Columns: 17\n",
      "\n",
      "Test  :  Records: 354 \n",
      "Columns: 17\n"
     ]
    }
   ],
   "source": [
    "print('Train : Records:', df_train.shape[0], '\\nColumns:', df_train.shape[1])\n",
    "print()\n",
    "\n",
    "print('Test  :  Records:', df_test.shape[0], '\\nColumns:', df_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Missing Values in Training Dataset: 0.242 %\n",
      "Proportion of Missing Values in Testing Dataset: 0.277 %\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of Missing Values in Training Dataset:', \n",
    "      round(df_train.isna().sum().sum()/len(df_train),3), '%')\n",
    "\n",
    "print('Proportion of Missing Values in Testing Dataset:', \n",
    "      round(df_test.isna().sum().sum()/len(df_test),3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values=df_train.values\n",
    "test_values=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(train_values)\n",
    "X_test=pd.DataFrame(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transform = DataFrameImputer().fit_transform(X_train)\n",
    "df_test_transform  = DataFrameImputer().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transform.columns=['Collision_Ref_No', 'Policing_Area', 'Collision_Severity', 'Weekday_of_Collision', 'Day_of_Collision',\n",
    "                            'Month_of_Collision', 'Hour_of_Collision', 'Carriageway_Type', 'Speed_Limit', 'Junction_Detail', \n",
    "                            'Junction_Control', 'Ped_Crossing_HC', 'Ped_Crossing_PC', 'Light_Conditions', 'Weather_Conditions',\n",
    "                            'Road_Surface_Conditions', 'Special_Conditions_at_Site']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_transform.columns=['Collision_Ref_No', 'Policing_Area', 'Collision_Severity', 'Weekday_of_Collision', 'Day_of_Collision',\n",
    "                            'Month_of_Collision', 'Hour_of_Collision', 'Carriageway_Type', 'Speed_Limit', 'Junction_Detail', \n",
    "                            'Junction_Control', 'Ped_Crossing_HC', 'Ped_Crossing_PC', 'Light_Conditions', 'Weather_Conditions',\n",
    "                            'Road_Surface_Conditions', 'Special_Conditions_at_Site']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_days = {'FRI': 5, 'MON': 1, 'SAT': 6, 'SUN': 7, 'THU': 4, 'TUE': 2, 'WED': 3}\n",
    "df_train_transform['Weekday_of_Collision'] = [week_days[day] for day in df_train_transform['Weekday_of_Collision']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train_transform['Collision_Severity']\n",
    "X = df_train_transform.drop(['Collision_Severity', 'Policing_Area'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "# sm = SMOTE(random_state=27)\n",
    "# X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916766228594185"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "smote = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "smote_pred = smote.predict(X_test)\n",
    "\n",
    "# Checking accuracy\n",
    "accuracy_score(y_test, smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Collision_Ref_No', 'Weekday_of_Collision', 'Day_of_Collision',\n",
       "       'Month_of_Collision', 'Hour_of_Collision', 'Carriageway_Type',\n",
       "       'Speed_Limit', 'Junction_Detail', 'Junction_Control', 'Ped_Crossing_HC',\n",
       "       'Ped_Crossing_PC', 'Light_Conditions', 'Weather_Conditions',\n",
       "       'Road_Surface_Conditions', 'Special_Conditions_at_Site'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X_train.columns))\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6725\n",
       "2     716\n",
       "1      91\n",
       "Name: Collision_Severity, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "X.Collision_Severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatal = X[X.Collision_Severity==1]\n",
    "serious = X[X.Collision_Severity==2]\n",
    "slight = X[X.Collision_Severity==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6725\n",
       "2    6725\n",
       "1    6725\n",
       "Name: Collision_Severity, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upsample minority\n",
    "fatal_upsampled = resample(fatal,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(slight), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "serious_upsampled = resample(serious,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(slight), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([fatal_upsampled, serious_upsampled, slight])\n",
    "\n",
    "# check new class counts\n",
    "upsampled.Collision_Severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Collision_Ref_No', 'Weekday_of_Collision', 'Day_of_Collision',\n",
       "       'Month_of_Collision', 'Hour_of_Collision', 'Carriageway_Type',\n",
       "       'Speed_Limit', 'Junction_Detail', 'Junction_Control', 'Ped_Crossing_HC',\n",
       "       'Ped_Crossing_PC', 'Light_Conditions', 'Weather_Conditions',\n",
       "       'Road_Surface_Conditions', 'Special_Conditions_at_Site'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = upsampled.Collision_Severity\n",
    "X_train = upsampled.drop(['Collision_Severity'], axis=1)\n",
    "upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5117483074472322"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upsampled=LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6725\n",
       "2    6725\n",
       "1    6725\n",
       "Name: Collision_Severity, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upsample minority\n",
    "fatal_upsampled = resample(fatal,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(slight), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "serious_upsampled = resample(serious,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(slight), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([fatal_upsampled, serious_upsampled, slight])\n",
    "\n",
    "# check new class counts\n",
    "upsampled.Collision_Severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Collision_Ref_No', 'Weekday_of_Collision', 'Day_of_Collision',\n",
       "       'Month_of_Collision', 'Hour_of_Collision', 'Carriageway_Type',\n",
       "       'Speed_Limit', 'Junction_Detail', 'Junction_Control', 'Ped_Crossing_HC',\n",
       "       'Ped_Crossing_PC', 'Light_Conditions', 'Weather_Conditions',\n",
       "       'Road_Surface_Conditions', 'Special_Conditions_at_Site'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = upsampled.Collision_Severity\n",
    "X_train = upsampled.drop(['Collision_Severity'], axis=1)\n",
    "\n",
    "upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5117483074472322"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upsampled=LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5487853444842692"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.028     0.483     0.052        29\n",
      "           2      0.144     0.395     0.211       243\n",
      "           3      0.946     0.566     0.708      2239\n",
      "\n",
      "    accuracy                          0.549      2511\n",
      "   macro avg      0.373     0.481     0.324      2511\n",
      "weighted avg      0.857     0.549     0.653      2511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report( y_test, upsampled_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
